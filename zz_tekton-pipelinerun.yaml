apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"tekton.dev/v1beta1","kind":"Pipeline","metadata":{"annotations":{},"name":"systesting","namespace":"user-lt"},"spec":{"params":[{"default":"systesting-demo","name":"run-id","type":"string"},{"default":"v4.0.9","name":"init-version","type":"string"},{"default":"v5.0.2","name":"target-version","type":"string"}],"tasks":[{"name":"env-prepare","params":[{"name":"run-id","value":"$(params.run-id)"},{"name":"init-version","value":"$(params.init-version)"}],"taskRef":{"name":"systesting-prepare-env"},"workspaces":[{"name":"manifest","workspace":"manifest"}]},{"name":"precheck-run","params":[{"name":"run-id","value":"$(params.run-id)"},{"name":"init-version","value":"$(params.init-version)"}],"runAfter":["env-prepare"],"taskRef":{"name":"systesting-precheck-run"},"workspaces":[{"name":"manifest","workspace":"manifest"}]},{"name":"upgrade","params":[{"name":"run-id","value":"$(params.run-id)"},{"name":"target-version","value":"$(params.target-version)"}],"runAfter":["precheck-run"],"taskRef":{"name":"systesting-upgrade-ops"},"workspaces":[{"name":"manifest","workspace":"manifest"}]},{"name":"postcheck-run","params":[{"name":"run-id","value":"$(params.run-id)"},{"name":"target-version","value":"$(params.target-version)"}],"runAfter":["upgrade"],"taskRef":{"name":"systesting-postcheck-run"},"workspaces":[{"name":"manifest","workspace":"manifest"}]}],"workspaces":[{"name":"manifest"}]}}
  creationTimestamp: "2021-09-22T06:10:57Z"
  generateName: systesting-demo-
  generation: 1
  labels:
    tekton.dev/pipeline: systesting
  name: systesting-demo-sgqmc
  namespace: user-lt
  resourceVersion: "406911905"
  selfLink: /apis/tekton.dev/v1beta1/namespaces/user-lt/pipelineruns/systesting-demo-sgqmc
  uid: 82a464e4-23c5-4ce8-901f-5927b1c53521
spec:
  params:
  - name: run-id
    value: systesting-demo
  - name: init-version
    value: v4.0.15
  - name: target-version
    value: v5.1.2
  pipelineRef:
    name: systesting
  serviceAccountName: system-testing
  timeout: 2h0m0s
  workspaces:
  - emptyDir: {}
    name: manifest
status:
  completionTime: "2021-09-22T06:39:00Z"
  conditions:
  - lastTransitionTime: "2021-09-22T06:39:00Z"
    message: 'Tasks Completed: 4 (Failed: 0, Cancelled 0), Skipped: 0'
    reason: Succeeded
    status: "True"
    type: Succeeded
  pipelineSpec:
    params:
    - default: systesting-demo
      name: run-id
      type: string
    - default: v4.0.9
      name: init-version
      type: string
    - default: v5.0.2
      name: target-version
      type: string
    tasks:
    - name: env-prepare
      params:
      - name: run-id
        value: $(params.run-id)
      - name: init-version
        value: $(params.init-version)
      taskRef:
        kind: Task
        name: systesting-prepare-env
      workspaces:
      - name: manifest
        workspace: manifest
    - name: precheck-run
      params:
      - name: run-id
        value: $(params.run-id)
      - name: init-version
        value: $(params.init-version)
      runAfter:
      - env-prepare
      taskRef:
        kind: Task
        name: systesting-precheck-run
      workspaces:
      - name: manifest
        workspace: manifest
    - name: upgrade
      params:
      - name: run-id
        value: $(params.run-id)
      - name: target-version
        value: $(params.target-version)
      runAfter:
      - precheck-run
      taskRef:
        kind: Task
        name: systesting-upgrade-ops
      workspaces:
      - name: manifest
        workspace: manifest
    - name: postcheck-run
      params:
      - name: run-id
        value: $(params.run-id)
      - name: target-version
        value: $(params.target-version)
      runAfter:
      - upgrade
      taskRef:
        kind: Task
        name: systesting-postcheck-run
      workspaces:
      - name: manifest
        workspace: manifest
    workspaces:
    - name: manifest
  startTime: "2021-09-22T06:10:57Z"
  taskRuns:
    systesting-demo-sgqmc-env-prepare-cfkkl:
      pipelineTaskName: env-prepare
      status:
        completionTime: "2021-09-22T06:12:40Z"
        conditions:
        - lastTransitionTime: "2021-09-22T06:12:40Z"
          message: All Steps have completed executing
          reason: Succeeded
          status: "True"
          type: Succeeded
        podName: systesting-demo-sgqmc-env-prepare-cfkkl-pod-9klvc
        startTime: "2021-09-22T06:10:57Z"
        steps:
        - container: step-generate-manifest
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: generate-manifest
          terminated:
            containerID: docker://043a70152c965bd13ff824b247fc3eca9c1d8a86cdc4fe71da9101d656fb8a51
            exitCode: 0
            finishedAt: "2021-09-22T06:11:04Z"
            reason: Completed
            startedAt: "2021-09-22T06:11:04Z"
        - container: step-apply-resources
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: apply-resources
          terminated:
            containerID: docker://7db4ca819f9d615b559ac72d0f07c854b72798ef2481d78df3f9d3d44c4d7f3c
            exitCode: 0
            finishedAt: "2021-09-22T06:11:07Z"
            reason: Completed
            startedAt: "2021-09-22T06:11:04Z"
        - container: step-wait-until-cluster-started
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: wait-until-cluster-started
          terminated:
            containerID: docker://ac28b3759a09079fb79b7e16900dba09a7f2565b2c964ea1dd2e114d013527c4
            exitCode: 0
            finishedAt: "2021-09-22T06:12:38Z"
            reason: Completed
            startedAt: "2021-09-22T06:11:07Z"
        taskSpec:
          params:
          - name: run-id
            type: string
          - name: init-version
            type: string
          steps:
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: generate-manifest
            resources: {}
            script: "#!/usr/bin/env bash\necho \"generating resources manifest...\"\ncat
              <<EOF > \"$(workspaces.manifest.path)/resources.yaml\"\napiVersion:
              naglfar.pingcap.com/v1\nkind: TestResourceRequest\nmetadata:\n  name:
              $(params.run-id)\nspec:\n  machines:\n     - name: m1\n     - name:
              m2\n  items:\n    - name: ctl\n      spec:\n        machine: m1\n        memory:
              64GB\n        cores: 32\n        disks:\n          disk1:\n            kind:
              nvme\n            size: 100GB\n            mountPath: /disks1\n    -
              name: haproxy\n      spec:\n        machine: m1\n        memory: 16GB\n
              \       cores: 2\n    - name: db\n      spec:\n        machine: m1\n
              \       memory: 8GB\n        cores: 4\n        disks:\n          disk1:\n
              \           kind: nvme\n            size: 50GB\n            mountPath:
              /disks1 \n    - name: kv\n      spec:\n        machine: m2\n        memory:
              64GB\n        cores: 32\n        disks:\n          disk1:\n            kind:
              nvme\n            size: 100GB\n            mountPath: /disks1  \n    -
              name: workload\n      spec:\n        machine: m2\n        memory: 4GB\n
              \       cores: 2\n    - name: workload2\n      spec:\n        machine:
              m2\n        memory: 4GB\n        cores: 2\nEOF\necho \"generating resources
              manifest...done\"\ncat \"$(workspaces.manifest.path)/resources.yaml\"\n\necho
              \"generating cluster manifest...\"\ncat <<EOF > \"$(workspaces.manifest.path)/cluster.yaml\"\napiVersion:
              naglfar.pingcap.com/v1\nkind: TestClusterTopology\nmetadata:\n  name:
              $(params.run-id)\nspec:\n  resourceRequest: $(params.run-id)\n  tidbCluster:\n
              \   tiupMirror: http://staging.tiup-server.pingcap.net\n    global:\n
              \     deployDir: \"/disks1/deploy\"\n      dataDir: \"/disks1/data\"
              \ \n    version:\n      version: $(params.init-version)\n    serverConfigs:\n
              \     pd: |-\n        replication.location-labels: [\"zone\", \"host\"]
              \n        enable-placement-rules: true\n        enable-redact-log: true\n
              \       schedule.low-space-ratio: 0.9 \n      tidb: |-\n        oom-use-tmp-storage:
              true\n        tmp-storage-path: \"/disks1/\"\n        tmp-storage-quota:
              8000000\n        repair-mode: true\n        new_collations_enabled_on_first_bootstrap:
              true\n        tikv-client.enable-chunk-rpc: false\n        tikv-client.store-liveness-timeout:
              \"2s\"\n        stmt-summary.enable-internal-query: true\n        prepared-plan-cache.enabled:
              true\n        oom-action: cancel\n        performance.max-memory: 5000\n
              \       performance.max-txn-ttl: 600000\n        performance.query-feedback-limit:
              1024\n        tikv-client.copr-cache.admission-min-process-ms: 5\n        alter-primary-key:
              true\n        enable-streaming: false\n        experimental.allow-expression-index:
              false\n        mem-quota-query: 10737418240\n      tikv: |-\n        gc.enable-compaction-filter:
              false\n        raftstore.early-apply: true\n        rocksdb.rate-bytes-per-sec:
              10GiB\n        storage.block-cache.capacity: 24GiB\n        storage.reserve-space:
              \"0MB\"\n\n    control: ctl\n    haProxy:\n      host: haproxy\n      port:
              9999\n      version: latest\n      config: |-\n        global\n          daemon\n
              \         maxconn 256\n        defaults\n          mode tcp\n          timeout
              connect 5000ms\n          timeout client 6000000ms\n          timeout
              server 6000000ms\n    tikv:\n      - host: kv\n        port: 20160\n
              \       statusPort: 20180\n        deployDir: /disk1/deploy/tikv-20160\n
              \       dataDir: /disk1/data/tikv-20160\n        logDir: /disk1/deploy/tikv-20160/log\n
              \       config: |-\n          server.labels:\n            zone: z1\n
              \           host: h1\n\n      - host: kv\n        port: 20260\n        statusPort:
              20280\n        deployDir: /disk1/deploy/tikv-20260\n        dataDir:
              /disk1/data/tikv-20260\n        logDir: /disk1/deploy/tikv-20260/log\n
              \       config: |-\n          server.labels:\n            zone: z1\n
              \           host: h2\n      - host: kv\n        port: 20360\n        statusPort:
              20380\n        deployDir: /disk1/deploy/tikv-20360\n        dataDir:
              /disk1/data/tikv-20360\n        logDir: /disk1/deploy/tikv-20360/log\n
              \       config: |-\n          server.labels:\n            zone: z1\n
              \           host: h3\n      - host: kv\n        port: 20460\n        statusPort:
              20480\n        deployDir: /disk1/deploy/tikv-20460\n        dataDir:
              /disk1/data/tikv-20460\n        logDir: /disk1/deploy/tikv-20460/log\n
              \       config: |-\n          server.labels:\n            zone: z1\n
              \           host: h4\n    tidb:\n      - host: db\n        port: 14000\n
              \       statusPort: 11080\n      - host: db\n        port: 4000\n        statusPort:
              10080\n\n    pd:\n      - host: ctl\n        clientPort: 2379\n        peerPort:
              2380\n        deployDir: /disk1/deploy/pd-2379\n        dataDir: /disk1/data/pd-2379\n
              \       logDir: /disk1/deploy/pd-2379/log\n        # config: |\n        #
              \    enable-placement-rules: true\n        #     schedule.low-space-ratio:
              0.9\n        #     replication.max-replicas: 1\n           \n      -
              host: ctl\n        clientPort: 12379\n        peerPort: 12380\n        deployDir:
              /disk1/deploy/pd-12379\n        dataDir: /disk1/data/pd-12379\n        logDir:
              /disk1/deploy/pd-12379/log\n        # config: |\n        #     enable-placement-rules:
              true\n        #     schedule.low-space-ratio: 0.9\n        #     replication.max-replicas:
              1\n            \n      - host: ctl\n        clientPort: 22379\n        peerPort:
              22380\n        deployDir: /disk1/deploy/pd-22379\n        dataDir: /disk1/data/pd-22379\n
              \       logDir: /disk1/deploy/pd-22379/log\n        # config: |\n        #
              \    enable-placement-rules: true\n        #     schedule.low-space-ratio:
              0.9\n        #     replication.max-replicas: 1  \n               \n
              \   tiflash:\n      - host: ctl\n        tcpPort: 19000\n    monitor:\n
              \     - host: ctl\n        port: 19090\n    grafana:\n      - host:
              ctl\n        port: 13000\n    alertmanager_servers:\n      - host: ctl\n
              \       webPort: 19093\n    cdc:\n      - host: ctl\n        port: 18300\nEOF\necho
              \"generating cluster manifest...done\"\ncat \"$(workspaces.manifest.path)/cluster.yaml\"\n"
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: apply-resources
            resources: {}
            script: |
              #!/usr/bin/env bash
              kubectl apply -f "$(workspaces.manifest.path)/resources.yaml"
              kubectl apply -f "$(workspaces.manifest.path)/cluster.yaml"
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: wait-until-cluster-started
            resources: {}
            script: |
              #!/usr/bin/env bash
              while true
              do
                state=`kubectl get tct "$(params.run-id)" -ojsonpath='{.status.state}' || echo unknown`
                echo "current resource state: $state"
                if [ "ready" = "$state" ]; then
                    break
                fi
                echo "test resources isn't ready now, wait another 10s..."
                sleep 10
              done
          workspaces:
          - mountPath: /adhoc-manifests
            name: manifest
    systesting-demo-sgqmc-postcheck-run-qcdb9:
      pipelineTaskName: postcheck-run
      status:
        completionTime: "2021-09-22T06:39:00Z"
        conditions:
        - lastTransitionTime: "2021-09-22T06:39:00Z"
          message: All Steps have completed executing
          reason: Succeeded
          status: "True"
          type: Succeeded
        podName: systesting-demo-sgqmc-postcheck-run-qcdb9-pod-fw9kl
        startTime: "2021-09-22T06:24:15Z"
        steps:
        - container: step-generate-run-manifest
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: generate-run-manifest
          terminated:
            containerID: docker://5a7f4025d855c72e08b71d9aa66a1103b5c2946570d9a090085b8c5afd451d99
            exitCode: 0
            finishedAt: "2021-09-22T06:24:28Z"
            reason: Completed
            startedAt: "2021-09-22T06:24:27Z"
        - container: step-workload-tail-f
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: workload-tail-f
          terminated:
            containerID: docker://e49531c744d43f638bc83a445e20b57080dbf11bd9fcb5d5299fcfa955b7b070
            exitCode: 0
            finishedAt: "2021-09-22T06:38:59Z"
            reason: Completed
            startedAt: "2021-09-22T06:24:29Z"
        taskSpec:
          params:
          - name: run-id
            type: string
          - default: v5.0.2
            name: target-version
            type: string
          steps:
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: generate-run-manifest
            resources: {}
            script: "#!/usr/bin/env bash\necho \"generating workload manifest...\"\nfile=\"$(workspaces.manifest.path)/run1.yaml\"\nctlip=`kubectl
              get tr | awk '$1 ~ /ctl/ {print $5}'`\nctlport=`kubectl get tr | awk
              '$1 ~ /ctl/ {print $4}'`\nctlclusterip=`kubectl get tr | awk '$1 ~ /ctl/
              {print $5}'`\nhaip=`kubectl get tr | awk '$1 ~ /haproxy/ {print $5}'`\necho
              \"ctl ip is ($ctlip), ctl port is ($ctlport)\"\ncat <<EOF > $file\napiVersion:
              naglfar.pingcap.com/v1\nkind: TestWorkload\nmetadata:\n  name: \"$(params.run-id)-postcheck-run\"\nspec:\n
              \ clusterTopologies:\n    - name: \"$(params.run-id)\"\n      aliasName:
              cluster\n  workloads:\n    - name: \"$(params.run-id)-postcheck\"\n
              \     dockerContainer:\n        resourceRequest:\n          name: \"$(params.run-id)\"\n
              \         node: workload2\n        image: hub-new.pingcap.net/migration-test/migration:v1\n
              \       imagePullPolicy: IfNotPresent\n        command:\n          -
              /bin/bash\n          - -c\n          - |\n            set -x\n\n            #
              tidbHost=\\`echo \\$cluster_tidb0 | awk -F \":\" '{print \\$1}'\\`\n
              \           # tidbPort=\\`echo \\$cluster_tidb0 | awk -F \":\" '{print
              \\$2}'\\`\n            tidbHost=$haip\n            tidbPort=9999\n            #-------test
              bank, will keep run during upgrade\n            cd /tools\n            \\`nohup
              ./bank --dsn \"root:@tcp(\\$tidbHost:\\$tidbPort)/bank?charset=utf8&parseTime=True\"
              --threads 5 --time 590 \\\n            --config config.yaml run > bank.log
              2>&1 & \\`\n            sleep 600s\n            tail -n 50 bank.log
              \n\n            # ------test dashboard, alert, grafana, prometheus\n
              \           cd /upgrade-test/\n            cat /upgrade-test/keywords/variables.robot\n
              \           tidbHoststr=\\`echo $tidbHost | sed 's/\\./\\\\\\\\./g'\\`\n
              \           ctlipstr=\\`echo $ctlip | sed 's/\\./\\\\\\\\./g'\\`\n            ctlportstr=\\`echo
              $ctlport\\`\n            targetver=\\`echo $(params.target-version)\\`\n
              \           #sed -i \"s/Chrome/headlessChrome/g\" keywords/variables.robot\n
              \           sed -i \"s/172\\.16\\.5\\.101/\\$ctlipstr/g\" keywords/variables.robot\n
              \           sed -i \"s/cluster_control_ip = \\\"172.16.5.101\\\"/cluster_control_ip
              = \\\"\\$ctlipstr\\\"/g\" config.toml\n            sed -i \"s/172\\.16\\.5\\.101/\\$ctlipstr/g\"
              config.toml\n            sed -i \"s/172\\.16\\.4\\.82/\\$ctlipstr/g\"
              config.toml\n            sed -i \"s/v5\\.0\\.0/\\$targetver/g\" config.toml\n
              \           echo \"ctl ip is ($ctlip), ctl port is ($ctlport)\"\n            #sed
              -i \"s/22/\\$ctlportstr/g\" config.toml\n\n            cat /upgrade-test/keywords/variables.robot\n
              \           cat /upgrade-test/config.toml\n\n            robot -i postcheck
              /upgrade-test/UI_testcase/tidb_dashboard.robot > result.txt\n            cat
              \"result.txt\"\n            robot -i postcheck /upgrade-test/UI_testcase/grafana.robot
              > g_result.txt\n            cat g_result.txt\n\n            cd /upgrade-test/API_TEST\n
              \           pytest prometheus_api_test.py\n            \n            #--------
              get system variables-------\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'show variables;' | tee /upgrade-test/postcheck-result/systemvariable-post.txt\n
              \           # cat /upgrade-test/postcheck-result/systemvariable-post.txt\n
              \           sleep 5s\n\n            #------- get tidb configs---------\n
              \           mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e \"select
              @@tidb_config\\\\G;\" > /upgrade-test/postcheck-result/postcheck-tidb.txt\n
              \           cat /upgrade-test/postcheck-result/postcheck-tidb.txt\n
              \           sleep 5s\n            ls /upgrade-test/postcheck-result/\n\n\n
              \           #--------get user privi-----------\n            mysql -uroot
              -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'show grants for qatest;' >
              /upgrade-test/postcheck-result/qatest-priv-post.txt\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'show grants for root;'
              >> /upgrade-test/postcheck-result/qatest-priv-post.txt\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'show grants for r1;'
              >> /upgrade-test/postcheck-result/qatest-priv-post.txt\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e \"show grants for test@'%';\"
              >> /upgrade-test/postcheck-result/qatest-priv-post.txt\n            cat
              /upgrade-test/postcheck-result/qatest-priv-post.txt\n            sleep
              2s\n\n            #-----------robot function test -------\n            cd
              /upgrade-test/Function_Test\n            pytest postcheck_test.py \n
              \           sleep 5s\n\n            #---------- test other sql --------\n
              \           mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'source
              /tools/sqltest/randtest.sql;' > /upgrade-test/postcheck-result/sqltest-result.txt\n
              \           cat /upgrade-test/postcheck-result/sqltest-result.txt\n
              \           sleep 5s\n\n            #--------get diff result-----------\n
              \           ls /upgrade-test/postcheck-result/\n            sleep 5s\n
              \           cat /upgrade-test/postcheck-result/pddiff.txt\n            cat
              /upgrade-test/postcheck-result/tidbdiff.txt\n            cat /upgrade-test/postcheck-result/vardiff.txt\n
              \           # cat /upgrade-test/postcheck-result/tiflashdiff.txt\n\n
              \           #------tiflash--------\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'desc select count(uid) from bank.account;' |tee
              /upgrade-test/postcheck-result/tiflash-postcheck.txt\n            count=\\`grep
              \"tiflash\" /upgrade-test/postcheck-result/tiflash-postcheck.txt | wc
              -l\\`\n            if [ \\$count -gt 0 ]; then\n                echo
              \"tiflash work normal\"\n            fi\n            cat /upgrade-test/postcheck-result/tiflash-postcheck.txt\n\n
              \           # get tiflash configs\n            echo \"select * from
              settings\" | curl 'http://\\$ctlip:8123/\\?'  --data-binary @- >> /upgrade-test/postcheck-result/tiflash-postcheck.txt\n
              \           cat /upgrade-test/postcheck-result/tiflash-postcheck.txt\n\n
              \           #--------sql binding----\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'show global bindings;' | tee /upgrade-test/show-global-binding.txt\n\n
              \           #--------expression index----\n            mysql -uroot
              -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'alter table test.t1 add index
              ((a  + b), (concat(c, d)));'\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'show create table test.t1;'\n\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'create table test.t2(a
              int, b int, c char, d varchar(20), primary key (a));'\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'alter table test.t2
              add index ((a  + b), (concat(c, d)));'\n            mysql -uroot -P
              \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'alter table test.t1 add index
              eidx ((lower(a)));'\n            mysql -uroot -P \"\\$tidbPort\" -h
              \"\\$tidbHost\" -e 'alter table test.t1 add index eidx1 ((upper(a)));'\n
              \           mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'alter
              table test.t1 add index eidx2 ((md5(a)));'\n            mysql -uroot
              -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'alter table test.t1 add index
              eidx3 ((reverse(a)));' \n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'alter table test.t1 add index eidx4 ((vitess_hash(a)));'\n
              \           mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'show
              create table test.t2;'\n\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'show create table test.t3;'\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'create table test.t4(a
              int, b int, index(( a * b + 1)));'\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'show create table test.t4;'\n\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'desc select a+1 from
              test.t group by a+1;'\n\n           \n            # #--------tptest----\n
              \           mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'create
              database tptest;'\n            cd /tools/tp-test\n            \\`nohup
              ./tp-test --store \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\"  run
              --dsn1 \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\" \\\n             --dsn2
              \"root:@tcp(172.16.6.77:4000)/test\" --test 100 > tptest.log 2>&1 &
              \\`\n            sleep 60\n            tail -n 50 tptest.log \n\n            #--------randgen----\n
              \           cd /tools/go-randgen-master\n            ./go-randgen exec
              -Y examples/functions.yy --dsn1 \"root:@tcp(\\$tidbHost:\\$tidbPort)/randgen\"
              --dsn2 \"root:@tcp(172.16.5.101:4000)/test\" \\\n             -Q 50
              --skip-zz --dump dump1 --maxrecur -1 > randgen.log\n            ./go-randgen
              exec -Y examples/interval.yy --dsn1 \"root:@tcp(\\$tidbHost:\\$tidbPort)/randgen\"
              --dsn2 \"root:@tcp(172.16.5.101:4000)/test\" \\\n             -Q 50
              --skip-zz --dump dump2 --maxrecur -1 >> randgen.log\n            ./go-randgen
              exec -Y examples/windows.yy --dsn1 \"root:@tcp(\\$tidbHost:\\$tidbPort)/randgen\"
              --dsn2 \"root:@tcp(172.16.5.101:4000)/test\" \\\n             -Q 50
              --skip-zz --dump dump3 --maxrecur -1 >> randgen.log\n            ./go-randgen
              exec -Y examples/postgres.yy --dsn1 \"root:@tcp(\\$tidbHost:\\$tidbPort)/randgen\"
              --dsn2 \"root:@tcp(172.16.5.101:4000)/test\" \\\n             -Q 50
              --skip-zz --dump dump4 --maxrecur -1 >> randgen.log \n            ./go-randgen
              exec -Y examples/subquery_test.yy --dsn1 \"root:@tcp(\\$tidbHost:\\$tidbPort)/randgen\"
              --dsn2 \"root:@tcp(172.16.6.77:4000)/test\" \\\n             -Q 50 --skip-zz
              --dump dump5 --maxrecur -1 >> randgen.log  \n            cat randgen.log
              \ \n            sleep 5s\n\n            #--------tpch----\n            cd
              /tools/go-tpc\n            \\`nohup ./bin/go-tpc tpch -H \\$tidbHost
              -P \\$tidbPort -D tpch run --time 600s > tpch.log 2>&1 & \\`\n            sleep
              120s\n            tail -n 50 tpch.log           \n            \nEOF\necho
              \"generating workload-run manifest...done\"\ncat \"$file\"\n"
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: workload-tail-f
            resources: {}
            script: |
              #!/usr/bin/env bash
              set -xe
              twName="$(params.run-id)-postcheck-run"
              echo "ensure test-workload($twName) does not exists"
              exists=`kubectl get tw $twName >/dev/null && echo "yes" || echo "no"`
              if [ "$exists" == "yes" ]; then
                echo "test workload($twName) already exists, delete it."
                kubectl delete tw $twName
              fi

              echo "create test-workload($twName)..."
              kubectl apply -f "$(workspaces.manifest.path)/run1.yaml"
              count=1000
              while true
              do
                state=`kubectl get tw "$twName" -ojsonpath='{.status.state}' || echo pending`
                echo "current workload state: $state"
                if [ "succeeded" == "$state" ]; then
                  break
                elif [ "failed" == "$state" ]; then
                  break
                elif [ "running" == "$state" ]; then
                  break
                elif [ $count -lt 0 ]; then
                  break
                fi
                echo "workload wait another 5s"
                sleep 20
                let "count--"
              done
              curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/PingCAP-QE/Naglfar/master/scripts/kubectl-naglfar-installer.sh | sh
              ~/.Naglfar/bin/naglfar logs $twName -n $(context.taskRun.namespace) --follow
              # kubectl delete tw $twName
          workspaces:
          - mountPath: /adhoc-manifests
            name: manifest
    systesting-demo-sgqmc-precheck-run-kqk67:
      pipelineTaskName: precheck-run
      status:
        completionTime: "2021-09-22T06:19:20Z"
        conditions:
        - lastTransitionTime: "2021-09-22T06:19:20Z"
          message: All Steps have completed executing
          reason: Succeeded
          status: "True"
          type: Succeeded
        podName: systesting-demo-sgqmc-precheck-run-kqk67-pod-6hrd5
        startTime: "2021-09-22T06:12:40Z"
        steps:
        - container: step-generate-run-manifest
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: generate-run-manifest
          terminated:
            containerID: docker://9c3adface71e695107a39839554d253b3853250e4404a0053e05eb1b8e32e245
            exitCode: 0
            finishedAt: "2021-09-22T06:12:46Z"
            reason: Completed
            startedAt: "2021-09-22T06:12:46Z"
        - container: step-workload-tail-f
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: workload-tail-f
          terminated:
            containerID: docker://d9d523580f4fd9237c1794c9ea938099cd9c2a96d94a059d0f64c3b2c5878db6
            exitCode: 0
            finishedAt: "2021-09-22T06:19:19Z"
            reason: Completed
            startedAt: "2021-09-22T06:12:47Z"
        taskSpec:
          params:
          - name: run-id
            type: string
          - default: v4.0.6
            name: init-version
            type: string
          steps:
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: generate-run-manifest
            resources: {}
            script: "#!/usr/bin/env bash\necho \"generating workload manifest...\"\nfile=\"$(workspaces.manifest.path)/run.yaml\"\nctlip=`kubectl
              get tr | awk '$1 ~ /ctl/ {print $5}'`\nctlport=`kubectl get tr | awk
              '$1 ~ /ctl/ {print $4}'`\nhaip=`kubectl get tr | awk '$1 ~ /haproxy/
              {print $5}'`\necho \"ctl ip is ($ctlip), ctl port is ($ctlport)\"\ncat
              <<EOF > $file\napiVersion: naglfar.pingcap.com/v1\nkind: TestWorkload\nmetadata:\n
              \ name: \"$(params.run-id)-precheck-run\"\nspec:\n  clusterTopologies:\n
              \   - name: \"$(params.run-id)\"\n      aliasName: cluster\n  workloads:\n
              \   - name: \"$(params.run-id)\"\n      dockerContainer:\n        resourceRequest:\n
              \         name: \"$(params.run-id)\"\n          node: workload\n        image:
              hub-new.pingcap.net/migration-test/migration:v1\n        imagePullPolicy:
              IfNotPresent\n        command:\n          - /bin/bash\n          - -c\n
              \         - |\n            set -x\n            # tidbHost=\\`echo \\$cluster_tidb0
              | awk -F \":\" '{print \\$1}'\\`\n            # tidbPort=\\`echo \\$cluster_tidb0
              | awk -F \":\" '{print \\$2}'\\`\n            tidbHost=$haip\n            tidbPort=9999\n\n
              \           #-------test bank, will keep run during upgrade\n            cd
              /tools\n            isBankExist=\\`mysql -uroot -P \"\\$tidbPort\" -h
              \"\\$tidbHost\" -e \"use bank; show tables;\" | grep customer > /dev/null
              && echo \"yes\" || echo \"no\"\\`\n            if [ \"\\$isBankExist\"
              == \"no\" ]; then\n              mysql -uroot -P\"\\$tidbPort\" -h \"\\$tidbHost\"
              -e \"create database bank;\"\n              echo \"\\`date\\` prepare...\"\n
              \             ./bank --dsn \"root:@tcp(\\$tidbHost:\\$tidbPort)/bank?charset=utf8&parseTime=True\"
              clean\n              ./bank --dsn \"root:@tcp(\\$tidbHost:\\$tidbPort)/bank?charset=utf8&parseTime=True\"
              --threads 50 --accounts 1000 --employees 1000 init \n              echo
              \"\\`date\\` init...done\"\n            else\n              echo \"database
              bank already exists\"\n            fi \n            \\`nohup ./bank
              --dsn \"root:@tcp(\\$tidbHost:\\$tidbPort)/bank?charset=utf8&parseTime=True\"
              --threads 5 --time 1000 \\\n              --config config.yaml run >
              bank.log 2>&1 & \\`\n            sleep 120\n            tail -n 50 bank.log
              \n\n            # ------test dashboard, alert, grafana, prometheus\n
              \           cd /upgrade-test/\n            cat keywords/variables.robot\n
              \           tidbHoststr=\\`echo $tidbHost | sed 's/\\./\\\\\\\\./g'\\`\n
              \           ctlipstr=\\`echo $ctlip | sed 's/\\./\\\\\\\\./g'\\`\n            ctlportstr=\\`echo
              $ctlport\\`\n            version=\\`echo $(params.init-version)\\`\n
              \           #sed -i \"s/Chrome/headlessChrome/g\" keywords/variables.robot\n
              \           sed -i \"s/172\\.16\\.5\\.101/\\$ctlipstr/g\" keywords/variables.robot\n
              \           #sed -i \"s/grafana_7_loc/\\grafana_loc/g\" keywords/variables.robot\n
              \           # sed -i \"s/Welcome to Grafana/Home Dashboard/g\" keywords/grafana_loc.robot\n
              \           sed -i \"s/cluster_control_ip = \\\"172.16.5.101\\\"/cluster_control_ip
              = \\\"\\$ctlipstr\\\"/g\" config.toml\n            sed -i \"s/172\\.16\\.5\\.101/\\$ctlipstr/g\"
              config.toml\n            sed -i \"s/172\\.16\\.4\\.82/\\$ctlipstr/g\"
              config.toml\n            sed -i \"s/v5\\.0\\.0/\\$version/g\" config.toml\n
              \           echo \"ctl ip is ($ctlip), ctl port is ($ctlport)\"\n            #
              sed -i \"s/22/\\$ctlportstr/g\" config.toml\n\n            cat keywords/variables.robot\n
              \           cat config.toml\n\n            robot -i precheck UI_testcase/tidb_dashboard.robot
              > result.txt\n            cat \"result.txt\"\n            robot -i precheck
              UI_testcase/grafana.robot > g_result.txt\n            cat g_result.txt\n
              \           cd /upgrade-test/API_TEST\n            pytest prometheus_api_test.py\n
              \           \n\n            # get system variables\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'show variables;' |
              tee /upgrade-test/precheck-result/systemvariable_pre.txt\n            #
              cat /upgrade-test/precheck-result/systemvariable_pre.txt\n            sleep
              5s\n\n            # get tidb configs\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e \"select @@tidb_config\\\\G;\"| tee /upgrade-test/precheck-result/precheck-tidb.txt\n
              \           cat /upgrade-test/precheck-result/precheck-tidb.txt\n            sleep
              5s\n            ls /upgrade-test/precheck-result\n\n\n            #----------
              create user and get user privi\n            #mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'create user qatest;grant Create on *.* to qatest;'\n
              \           mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'source
              /tools/sqltest/authfile.sql;' > /upgrade-test/precheck-result/qatest-priv-pre.txt\n
              \           cat /upgrade-test/precheck-result/qatest-priv-pre.txt\n
              \           sleep 5s\n\n\n            #------test cluster_status, config
              default value, system variables\n            cd /upgrade-test/Function_Test\n
              \           pytest precheck_test.py \n            sleep 5s\n\n            #------tiflash--------\n
              \           mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'alter
              table bank.account SET TIFLASH REPLICA 1;' \n            sleep 30s\n
              \           mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e \"SELECT
              * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = 'bank'
              and TABLE_NAME = 'account';\"\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'desc select count(uid) from bank.account;' |
              tee /upgrade-test/precheck-result/tiflash-precheck.txt\n            count=\\`grep
              \"tiflash\" /upgrade-test/precheck-result/tiflash-precheck.txt | wc
              -l\\`\n            if [ \\$count -gt 0 ]; then\n                echo
              \"tiflash work normal\"\n            fi\n            cat /upgrade-test/precheck-result/tiflash-precheck.txt\n\n
              \           # get tiflash configs\n            \\`echo \"select * from
              settings\" | curl 'http://\\$ctlip:8123/\\?' --data-binary @- >> /upgrade-test/precheck-result/tiflash-precheck.txt\\`\n
              \           cat /upgrade-test/precheck-result/tiflash-precheck.txt\n\n
              \           #--------sql binding----\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'source /tools/sqltest/binding1.test;' \n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'source /tools/sqltest/binding2.test;'
              \n            sleep 5s\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'show global bindings;'\n\n            #--------expression
              index----\n            mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\"
              -e 'create table test.t1(a int, b int, c char, d varchar(20), primary
              key (a));'\n            mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\"
              -e 'create table test.t3(a int, b int, c char, d varchar(20), primary
              key (a));'\n            mysql -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\"
              -e 'alter table test.t3 add index ((a  + b), (concat(c, d)));'\n\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'create table test.t5(a
              int, b bigint AS (a+1) virtual, index idx_b(b));'\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'desc select a+1 from
              test.t5 group by a+1;'\n\n            #--------tptest----\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'create database tptest;'\n
              \           cd /tools/tp-test\n            ./tp-test --store \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\"
              clear\n            ./tp-test --store \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\"
              init\n            ./tp-test --store \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\"
              gen ./scenarios/general1.yy --test 20\n            ./tp-test --store
              \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\" gen ./scenarios/general2.yy
              --test 20\n            ./tp-test --store \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\"
              gen ./scenarios/multi-table.yy --test 20\n            ./tp-test --store
              \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\" gen ./scenarios/prepared-stmt.yy
              --test 20\n            ./tp-test --store \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\"
              gen ./scenarios/general1_exp.yy --test 20\n            # \\`nohup ./tp-test
              --store \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\"  run --dsn1 \"root:@tcp(\\$tidbHost:\\$tidbPort)/tptest\"
              \\\n            #  --dsn2 \"root:@tcp(172.16.5.101:4000)/test\" --test
              100 > tptest.log 2>&1 & \\`\n            # sleep 1000s\n            #
              tail -n 50 tptest.log \n\n            #--------randgen----\n            mysql
              -uroot -P \"\\$tidbPort\" -h \"\\$tidbHost\" -e 'drop database if exists
              randgen; create database randgen;'\n            cd /tools/go-randgen-master\n
              \           ./go-randgen gendata --dsns \"root:@tcp(\\$tidbHost:\\$tidbPort)/randgen,root:@tcp(172.16.6.77:4000)/test\"
              > randgen.log\n            cat randgen.log\n\n            #--------tpch----\n
              \           cd /tools/go-tpc\n            mysql -uroot -P \"\\$tidbPort\"
              -h \"\\$tidbHost\" -e 'drop database if exists tpch; create database
              tpch;'\n            \\`nohup ./bin/go-tpc tpch -H \\$tidbHost -P \\$tidbPort
              -D tpch --sf 1 --analyze --tiflash prepare > tpch.log 2>&1 & \\`\n            sleep
              60s\n            tail -n 50 tpch.log\n\n\n                               \nEOF\necho
              \"generating workload-run manifest...done\"\ncat \"$file\"\n"
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: workload-tail-f
            resources: {}
            script: |
              #!/usr/bin/env bash
              set -xe
              twName="$(params.run-id)-precheck-run"
              echo "ensure test-workload($twName) does not exists"
              exists=`kubectl get tw $twName >/dev/null && echo "yes" || echo "no"`
              if [ "$exists" == "yes" ]; then
                echo "test workload($twName) already exists, delete it."
                kubectl delete tw $twName
              fi

              echo "create test-workload($twName)..."
              kubectl apply -f "$(workspaces.manifest.path)/run.yaml"
              count=200
              while true
              do
                state=`kubectl get tw "$twName" -ojsonpath='{.status.state}' || echo pending`
                echo "current workload state: $state"
                if [ "succeeded" == "$state" ]; then
                  break
                elif [ "failed" == "$state" ]; then
                  break
                elif [ "running" == "$state" ]; then
                  break
                elif [ $count -lt 0 ]; then
                  break
                fi
                echo "workload wait another 5s"
                sleep 20
                let "count--"
              done
              curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/PingCAP-QE/Naglfar/master/scripts/kubectl-naglfar-installer.sh | sh
              ~/.Naglfar/bin/naglfar logs $twName -n $(context.taskRun.namespace) --follow
              # kubectl delete tw $twName
          workspaces:
          - mountPath: /adhoc-manifests
            name: manifest
    systesting-demo-sgqmc-upgrade-nldpg:
      pipelineTaskName: upgrade
      status:
        completionTime: "2021-09-22T06:24:15Z"
        conditions:
        - lastTransitionTime: "2021-09-22T06:24:15Z"
          message: All Steps have completed executing
          reason: Succeeded
          status: "True"
          type: Succeeded
        podName: systesting-demo-sgqmc-upgrade-nldpg-pod-z7n2f
        startTime: "2021-09-22T06:19:20Z"
        steps:
        - container: step-generate-manifest
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: generate-manifest
          terminated:
            containerID: docker://ebbe3430a6623d1300e3a20d53568c7937e74117213776586be1842c41517ba1
            exitCode: 0
            finishedAt: "2021-09-22T06:19:27Z"
            reason: Completed
            startedAt: "2021-09-22T06:19:27Z"
        - container: step-wait-until-cluster-started
          imageID: docker-pullable://hub.pingcap.net/qa/kubetools@sha256:59210fd139a17bb37e52020edf50cf32d018d8c5a2211ff3321b2017db5e4927
          name: wait-until-cluster-started
          terminated:
            containerID: docker://ac2fccb11976ab074885ec2196bfe47e36c7383827fedc56292e8930604c2531
            exitCode: 0
            finishedAt: "2021-09-22T06:24:13Z"
            reason: Completed
            startedAt: "2021-09-22T06:19:28Z"
        taskSpec:
          params:
          - name: run-id
            type: string
          - name: target-version
            type: string
          steps:
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: generate-manifest
            resources: {}
            script: "#!/usr/bin/env bash\nkubectl patch tct $(params.run-id)  --type=json
              -p='[{\"op\": \"replace\", \"path\": \"/spec/tidbCluster/version/version\",\"value\":\"$(params.target-version)\"}]'
              \n"
          - image: hub.pingcap.net/qa/kubetools:20200730
            name: wait-until-cluster-started
            resources: {}
            script: |
              #!/usr/bin/env bash
              count=30
              while true
              do
                state=`kubectl get tct "$(params.run-id)" -ojsonpath='{.status.state}' || echo unknown`
                echo "current resource state: $state"
                if [ "ready" = "$state" ]; then
                    break
                elif [ $count -lt 0 ]; then
                    break
                fi
                echo "test resources isn't ready now, wait another 10s..."
                sleep 10
                let "count--"
              done
          workspaces:
          - mountPath: /adhoc-manifests
            name: manifest